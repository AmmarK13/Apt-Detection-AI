{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee28837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "246a799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_data(test_data, reference_data, model_features):\n",
    "    \"\"\"Handle missing columns and missing values in the test data by sampling from reference data.\"\"\"\n",
    "    for col in model_features:\n",
    "        if col not in test_data.columns:\n",
    "            # Sample from reference data if column is missing\n",
    "            sampled_value = reference_data[col].dropna().sample(1).values[0]\n",
    "            test_data[col] = sampled_value\n",
    "        else:\n",
    "            # Handle missing values in existing columns\n",
    "            if test_data[col].isnull().sum() > 0:\n",
    "                sampled_values = reference_data[col].dropna()\n",
    "                if not sampled_values.empty:\n",
    "                    test_data[col] = test_data[col].apply(\n",
    "                        lambda x: random.choice(sampled_values) if pd.isna(x) else x\n",
    "                    )\n",
    "                else:\n",
    "                    test_data[col] = test_data[col].fillna(0)  # If no data to sample from, fill with 0\n",
    "    \n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "582b0ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_model_features(df, model_features, training_df=None):\n",
    "    \"\"\"Ensure the dataframe has exactly the model_features, adding missing ones with mean values and dropping extras.\"\"\"\n",
    "    # Add missing columns (with mean values from training_df if provided)\n",
    "    missing_cols = set(model_features) - set(df.columns)\n",
    "    if missing_cols:\n",
    "        print(f\"Adding missing columns: {missing_cols}\")\n",
    "        for col in missing_cols:\n",
    "            # If training_df is provided, use its mean value for the missing columns\n",
    "            if training_df is not None and col in training_df.columns:\n",
    "                df[col] = training_df[col].mean()\n",
    "            else:\n",
    "                df[col] = np.nan  # In case training_df is not provided, fill with NaN\n",
    "    # Drop extra columns not in model_features\n",
    "    extra_cols = set(df.columns) - set(model_features)\n",
    "    if extra_cols:\n",
    "        print(f\"Dropping extra columns: {extra_cols}\")\n",
    "        df.drop(columns=extra_cols, inplace=True)\n",
    "    \n",
    "    # Ensure the columns are ordered the same as in model_features\n",
    "    df = df[model_features]\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4db678d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding missing columns: {'Bwd IAT Std', 'Fwd Pkts/b Avg', 'Init Bwd Win Byts', 'Active Std', 'Flow Byts/s', 'Bwd Pkt Len Mean', 'Bwd URG Flags', 'Fwd Seg Size Min', 'Init Fwd Win Byts', 'Flow IAT Min', 'Active Max', 'Bwd Pkt Len Std', 'Bwd Pkt Len Max', 'Fwd PSH Flags', 'Flow IAT Std', 'Flow Duration', 'Bwd Header Len', 'Active Min', 'PSH Flag Cnt', 'Flow Pkts/s', 'Timestamp', 'Bwd IAT Mean', 'Fwd Header Len', 'Fwd IAT Max', 'Flow IAT Max', 'Fwd Byts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Pkts/s', 'Flow IAT Mean', 'Pkt Len Var', 'Bwd Pkt Len Min', 'URG Flag Cnt', 'Idle Mean', 'Bwd Byts/b Avg', 'Fwd Pkt Len Min', 'TotLen Bwd Pkts', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Fwd URG Flags', 'Down/Up Ratio', 'Bwd IAT Tot', 'Idle Std', 'Tot Fwd Pkts', 'Bwd IAT Max', 'Pkt Len Std', 'FIN Flag Cnt', 'Pkt Len Mean', 'Bwd Pkts/b Avg', 'Active Mean', 'CWE Flag Count', 'Fwd Pkts/s', 'RST Flag Cnt', 'Fwd Act Data Pkts', 'Dst Port', 'Bwd Blk Rate Avg', 'Bwd PSH Flags', 'TotLen Fwd Pkts', 'ACK Flag Cnt', 'Bwd IAT Min', 'Fwd IAT Std'}\n",
      "      Dst Port  Protocol     Timestamp  Flow Duration  Tot Fwd Pkts  \\\n",
      "0  4617.868859       6.0  1.518595e+09   6.366756e+06      5.005059   \n",
      "1  4617.868859      17.0  1.518595e+09   6.366756e+06      5.005059   \n",
      "2  4617.868859       6.0  1.518595e+09   6.366756e+06      5.005059   \n",
      "\n",
      "   Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  \\\n",
      "0          12.0       379.224057        834.74955            161.0   \n",
      "1           1.0       379.224057        834.74955           1200.0   \n",
      "2          30.0       379.224057        834.74955            500.0   \n",
      "\n",
      "   Fwd Pkt Len Min  ...  Init Fwd Win Byts  Init Bwd Win Byts  \\\n",
      "0         8.315534  ...       10683.062859        6300.939133   \n",
      "1         8.315534  ...       10683.062859        6300.939133   \n",
      "2         8.315534  ...       10683.062859        6300.939133   \n",
      "\n",
      "   Fwd Act Data Pkts  Fwd Seg Size Min   Active Mean   Active Std  \\\n",
      "0           2.648352         23.429159  14708.231283  7105.414414   \n",
      "1           2.648352         23.429159  14708.231283  7105.414414   \n",
      "2           2.648352         23.429159  14708.231283  7105.414414   \n",
      "\n",
      "     Active Max    Active Min     Idle Mean      Idle Std  \n",
      "0  32606.278532  11848.836314  1.143227e+06  17195.586791  \n",
      "1  32606.278532  11848.836314  1.143227e+06  17195.586791  \n",
      "2  32606.278532  11848.836314  1.143227e+06  17195.586791  \n",
      "\n",
      "[3 rows x 63 columns]\n",
      "Shape after processing: (3, 63)\n",
      "Missing values remaining: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_features = [\n",
    "    'Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts',\n",
    "    'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min',\n",
    "    'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min',\n",
    "    'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s',\n",
    "    'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Std',\n",
    "    'Fwd IAT Max', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max',\n",
    "    'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags',\n",
    "    'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Mean',\n",
    "    'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt',\n",
    "    'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'Down/Up Ratio', 'Fwd Byts/b Avg',\n",
    "    'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg',\n",
    "    'Bwd Blk Rate Avg', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts',\n",
    "    'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
    "    'Idle Std'\n",
    "]\n",
    "training_df=pd.read_csv(r\"D:\\4th semester\\SE\\project\\Datasets\\step_4.csv\")\n",
    "test_data = pd.DataFrame({\n",
    "    'Protocol': [6.0, 17.0, np.nan],\n",
    "    'Tot Bwd Pkts': [12.0, np.nan, 30.0],\n",
    "    'Fwd Pkt Len Max': [np.nan, 1200.0, 500.0],\n",
    "    # Not including all 63 features\n",
    "})\n",
    "from copy import deepcopy\n",
    "test_copy = deepcopy(test_data)\n",
    "test_copy = match_model_features(test_copy, model_features, training_df)\n",
    "test_copy = handle_missing_data(test_copy, training_df, model_features)\n",
    "\n",
    "print(test_copy.head())\n",
    "print(\"Shape after processing:\", test_copy.shape)\n",
    "print(\"Missing values remaining:\", test_copy.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1abc2e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min values: [7.04663125e-02 0.00000000e+00 5.75235799e-01 5.30563001e-02\n",
      " 1.51706775e-02 1.08695652e-02 1.36953433e-02 1.53659868e-03\n",
      " 0.00000000e+00 6.06973250e-02 9.16103324e-02 7.56640136e-02\n",
      " 2.14624648e-01 6.01961433e-02 6.90170425e-02 1.10310047e-01\n",
      " 3.27926526e-03 1.35329553e-01 1.56701823e-02 5.13169950e-03\n",
      " 2.35574726e-02 1.37968138e-02 4.84191034e-03 2.20493071e-02\n",
      " 3.03179768e-02 1.89789780e-02 1.59376284e-02 1.21739333e-02\n",
      " 3.04249134e-03 2.26961409e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.99161911e-02 1.28028598e-02 7.03200066e-02\n",
      " 1.30019092e-01 7.30919944e-02 1.20860664e-01 4.91589665e-02\n",
      " 0.00000000e+00 4.05223238e-02 5.21539476e-01 2.64041927e-01\n",
      " 1.25382629e-01 0.00000000e+00 1.64617737e-01 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.63025862e-01 9.61599599e-02 6.62088059e-02\n",
      " 4.88107471e-01 3.61600030e-03 4.57198471e-03 6.21860728e-03\n",
      " 2.99223768e-03 9.52763017e-03 2.44892671e-04]\n",
      "Max values: [7.04663125e-02 1.00000000e+00 5.75235799e-01 5.30563001e-02\n",
      " 1.51706775e-02 6.52173913e-02 1.36953433e-02 1.53659868e-03\n",
      " 8.21917808e-01 6.06973250e-02 9.16103324e-02 7.56640136e-02\n",
      " 2.14624648e-01 6.01961433e-02 6.90170425e-02 1.10310047e-01\n",
      " 3.27926526e-03 1.35329553e-01 1.56701823e-02 5.13169950e-03\n",
      " 2.35574726e-02 1.37968138e-02 4.84191034e-03 2.20493071e-02\n",
      " 3.03179768e-02 1.89789780e-02 1.59376284e-02 1.21739333e-02\n",
      " 3.04249134e-03 2.26961409e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.99161911e-02 1.28028598e-02 7.03200066e-02\n",
      " 1.30019092e-01 7.30919944e-02 1.20860664e-01 4.91589665e-02\n",
      " 0.00000000e+00 4.05223238e-02 5.21539476e-01 2.64041927e-01\n",
      " 1.25382629e-01 0.00000000e+00 1.64617737e-01 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.63025862e-01 9.61599599e-02 6.62088059e-02\n",
      " 4.88107471e-01 3.61600030e-03 4.57198471e-03 6.21860728e-03\n",
      " 2.99223768e-03 9.52763017e-03 2.44892671e-04]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "scaler = joblib.load(r'D:\\4th semester\\SE\\project\\Models\\min_max_scaler.pkl')  # Your saved fitted scaler\n",
    "new_data_scaled = scaler.transform(test_copy) \n",
    "\n",
    "\n",
    "print(\"Min values:\", np.min(new_data_scaled, axis=0))\n",
    "print(\"Max values:\", np.max(new_data_scaled, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a551328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dummy dataset saved to dummy_model_features.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# List of model features\n",
    "model_features = [\n",
    "    'Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts',\n",
    "    'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min',\n",
    "    'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min',\n",
    "    'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s',\n",
    "    'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Std',\n",
    "    'Fwd IAT Max', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max',\n",
    "    'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags',\n",
    "    'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Mean',\n",
    "    'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt',\n",
    "    'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'Down/Up Ratio', 'Fwd Byts/b Avg',\n",
    "    'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg',\n",
    "    'Bwd Blk Rate Avg', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts',\n",
    "    'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
    "    'Idle Std'\n",
    "]\n",
    "\n",
    "# Generate 3 dummy rows\n",
    "dummy_data = []\n",
    "\n",
    "for _ in range(3):\n",
    "    row = []\n",
    "    for feature in model_features:\n",
    "        if feature == 'Timestamp':\n",
    "            # Generate a random datetime and convert to string in expected format\n",
    "            time = datetime(2024, 1, 1, 12, 0, 0) + timedelta(minutes=np.random.randint(0, 1000))\n",
    "            row.append(time.strftime('%d/%m/%Y %H:%M:%S'))\n",
    "        elif feature in ['Protocol', 'Dst Port']:\n",
    "            row.append(np.random.randint(1, 255))\n",
    "        elif 'Flag' in feature or 'Ratio' in feature or 'CWE' in feature:\n",
    "            row.append(np.random.randint(0, 2))\n",
    "        elif 'Win' in feature or 'Pkt' in feature or 'Byts' in feature:\n",
    "            row.append(np.random.randint(1, 10000))\n",
    "        else:\n",
    "            row.append(np.round(np.random.uniform(0.01, 1000), 2))\n",
    "    dummy_data.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "df_dummy = pd.DataFrame(dummy_data, columns=model_features)\n",
    "\n",
    "# Save to CSV (optional)\n",
    "df_dummy.to_csv(\"dummy_model_features.csv\", index=False)\n",
    "print(\"✅ Dummy dataset saved to dummy_model_features.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82e5762f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dst Port  Protocol            Timestamp  Flow Duration  Tot Fwd Pkts  \\\n",
      "0        86       249  01/01/2024 17:09:00         784.90          9658   \n",
      "1       189        57  01/01/2024 13:45:00         858.30          6305   \n",
      "2       253        74  01/01/2024 16:41:00         266.63          4226   \n",
      "\n",
      "   Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  \\\n",
      "0          7438             3808             3802             2552   \n",
      "1           584              947             7929             3923   \n",
      "2          4619             8255             4254             9351   \n",
      "\n",
      "   Fwd Pkt Len Min  ...  Init Fwd Win Byts  Init Bwd Win Byts  \\\n",
      "0              717  ...               7726               9056   \n",
      "1             5762  ...               9359               8541   \n",
      "2             6319  ...               7195               9246   \n",
      "\n",
      "   Fwd Act Data Pkts  Fwd Seg Size Min  Active Mean  Active Std  Active Max  \\\n",
      "0               1488            711.18       875.05      198.77      289.26   \n",
      "1               6783            690.65        99.16       25.77      847.59   \n",
      "2               4482             64.12       473.47      211.11       97.66   \n",
      "\n",
      "   Active Min  Idle Mean  Idle Std  \n",
      "0      268.72     248.34    689.57  \n",
      "1      986.48      87.97    859.63  \n",
      "2      384.42      21.11    468.42  \n",
      "\n",
      "[3 rows x 63 columns]\n",
      "Shape after processing: (3, 63)\n",
      "Missing values remaining: 0\n"
     ]
    }
   ],
   "source": [
    "training_df=pd.read_csv(r\"D:\\4th semester\\SE\\project\\Datasets\\step_4.csv\")\n",
    "\n",
    "from copy import deepcopy\n",
    "df_dummy  = deepcopy(df_dummy )\n",
    "df_dummy  = match_model_features(df_dummy , model_features, training_df)\n",
    "df_dummy = handle_missing_data(df_dummy , training_df, model_features)\n",
    "\n",
    "print(df_dummy.head())\n",
    "print(\"Shape after processing:\", df_dummy.shape)\n",
    "print(\"Missing values remaining:\", df_dummy.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c26493c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of    Dst Port  Protocol   Timestamp  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  \\\n",
      "0        86       249  1704128940         784.90          9658          7438   \n",
      "1       189        57  1704116700         858.30          6305           584   \n",
      "2       253        74  1704127260         266.63          4226          4619   \n",
      "\n",
      "   TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  ...  \\\n",
      "0             3808             3802             2552              717  ...   \n",
      "1              947             7929             3923             5762  ...   \n",
      "2             8255             4254             9351             6319  ...   \n",
      "\n",
      "   Init Fwd Win Byts  Init Bwd Win Byts  Fwd Act Data Pkts  Fwd Seg Size Min  \\\n",
      "0               7726               9056               1488            711.18   \n",
      "1               9359               8541               6783            690.65   \n",
      "2               7195               9246               4482             64.12   \n",
      "\n",
      "   Active Mean  Active Std  Active Max  Active Min  Idle Mean  Idle Std  \n",
      "0       875.05      198.77      289.26      268.72     248.34    689.57  \n",
      "1        99.16       25.77      847.59      986.48      87.97    859.63  \n",
      "2       473.47      211.11       97.66      384.42      21.11    468.42  \n",
      "\n",
      "[3 rows x 63 columns]>\n"
     ]
    }
   ],
   "source": [
    "def convert_timestamp(df):\n",
    "    \"\"\"Convert 'Timestamp' column to seconds.\"\"\"\n",
    "    if 'Timestamp' in df.columns:\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%d/%m/%Y %H:%M:%S', errors='coerce')\n",
    "        df['Timestamp'] = (df['Timestamp'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "    return df\n",
    "\n",
    "df_dummy=convert_timestamp(df_dummy)\n",
    "\n",
    "print(df_dummy.head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eee499db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved to: D:\\4th semester\\SE\\project\\Models\\min_max_scaler.pkl\n",
      "<bound method NDFrame.head of    Dst Port  Protocol  Timestamp  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  \\\n",
      "0  0.000000  1.000000   1.000000       0.875944      1.000000      1.000000   \n",
      "1  0.616766  0.000000   0.000000       1.000000      0.382732      0.000000   \n",
      "2  1.000000  0.088542   0.862745       0.000000      0.000000      0.588707   \n",
      "\n",
      "   TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  ...  \\\n",
      "0         0.391489         0.000000         0.000000         0.000000  ...   \n",
      "1         0.000000         1.000000         0.201647         0.900571  ...   \n",
      "2         1.000000         0.109523         1.000000         1.000000  ...   \n",
      "\n",
      "   Init Fwd Win Byts  Init Bwd Win Byts  Fwd Act Data Pkts  Fwd Seg Size Min  \\\n",
      "0           0.245379           0.730496           0.000000          1.000000   \n",
      "1           1.000000           0.000000           1.000000          0.968272   \n",
      "2           0.000000           1.000000           0.565439          0.000000   \n",
      "\n",
      "   Active Mean  Active Std  Active Max  Active Min  Idle Mean  Idle Std  \n",
      "0     1.000000     0.93342    0.255491    0.000000   1.000000  0.565297  \n",
      "1     0.000000     0.00000    1.000000    1.000000   0.294239  1.000000  \n",
      "2     0.482427     1.00000    0.000000    0.161196   0.000000  0.000000  \n",
      "\n",
      "[3 rows x 63 columns]>\n"
     ]
    }
   ],
   "source": [
    "def scale_features(df, scaler_save_path):\n",
    "    \"\"\"Scale features except 'Label' using MinMaxScaler and save scaler.\"\"\"\n",
    "    feature_cols = [col for col in df.columns if col != 'Label']\n",
    "    scaler = MinMaxScaler()\n",
    "    df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
    "    joblib.dump(scaler, scaler_save_path)\n",
    "    print(f\"Scaler saved to: {scaler_save_path}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "df_dummy=scale_features(df_dummy,r\"D:\\4th semester\\SE\\project\\Models\\min_max_scaler.pkl\")\n",
    "\n",
    "print(df_dummy.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51524f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded successfully!\n",
      "Model details: RandomForestClassifier(random_state=42)\n",
      "✅ Model loaded successfully!\n",
      "Model details: RandomForestClassifier(random_state=42)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Attempt to load the model\n",
    "    \n",
    "try:\n",
    "    model = joblib.load(r'D:\\4th semester\\SE\\project\\Models_final\\balanced_FTP-BruteForce_model.pkl')  # Replace with your actual model file name\n",
    "    print(\"✅ Model loaded successfully!\")\n",
    "    \n",
    "    # Optional: Check model type or summary\n",
    "    print(\"Model details:\", model)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Model file not found.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Error loading model:\", str(e))\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    model = joblib.load(r'D:\\4th semester\\SE\\project\\Models_final\\balanced_SSH-BruteForce_model.pkl')  # Replace with your actual model file name\n",
    "    print(\"✅ Model loaded successfully!\")\n",
    "    \n",
    "    # Optional: Check model type or summary\n",
    "    print(\"Model details:\", model)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Model file not found.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Error loading model:\", str(e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
